# Key points
# For  k -fold cross validation, we divide the dataset into a training set and 
# a test set. We train our algorithm exclusively on the training set and use 
# the test set only for evaluation purposes. 
# For each set of algorithm parameters being considered, we want an estimate 
# of the MSE and then we will choose the parameters with the smallest MSE. In 
# k -fold cross validation, we randomly split the observations into  k  non-overlapping 
# sets, and repeat the calculation for MSE for each of these sets. Then, we compute
# the average MSE and obtain an estimate of our loss. Finally, we can select the
# optimal parameter that minimized the MSE.
# In terms of how to select  k  for cross validation, larger values of  k  are preferable
# but they will also take much more computational time. For this reason, the choices of 
# k=5  and  k=10  are common.

library(tidyverse)
library(caret)

# set.seed(1996) #if you are using R 3.5 or earlier
set.seed(1996, sample.kind="Rounding") #if you are using R 3.6 or later
n <- 1000
p <- 10000
x <- matrix(rnorm(n*p), n, p)
colnames(x) <- paste("x", 1:ncol(x), sep = "_")
y <- rbinom(n, 1, 0.5) %>% factor()
rnum(y)

x_subset <- x[ ,sample(p, 100)]
fit <- train(x_subset, y, method = "glm")
fit$results

install.packages("BiocManager")
BiocManager::install("genefilter")
library(genefilter)
tt <- colttests(x, y)
pvals <- tt$p.value

ind <- which(pvals <=0.01)
length(ind)

x_subset <- x[, ind]
fit <- train(x_subset, y, method = "glm")
fit$results

library(dslabs)
library(caret)
data("tissue_gene_expression")  
dat <- tissue_gene_expression$x
y <- tissue_gene_expression$y
kk <- seq(1,7,2)
set.seed(1, sample.kind="Rounding")
fit <- train(dat, y,method = "knn", tuneGrid=data.frame(k=kk))
fit

----------------------------------------------------------------------------------------------------
# Bootstrap
  
# Key points
# When we don't have access to the entire population, we can use bootstrap to estimate 
# the population median  m  .
# The bootstrap permits us to approximate a Monte Carlo simulation without access to the 
# entire distribution. The general idea is relatively simple. We act as if the observed 
# sample is the population. We then sample datasets (with replacement) of the same sample
# size as the original dataset. Then we compute the summary statistic, in this case the
# median, on this bootstrap sample.
# Note that we can use ideas similar to those used in the bootstrap in cross validation:
# instead of dividing the data into equal partitions, we simply bootstrap many times.

library(ggplot2)
n <- 10^6
income <- 10^(rnorm(n, log10(45000), log10(3)))
qplot(log10(income), bins = 30, color = I("black"))

m <- median(income)
m

set.seed(1, sample.kind="Rounding")
#use set.seed(1, sample.kind="Rounding") instead if using R 3.6 or later
N <- 250
X <- sample(income, N)
M<- median(X)
M

library(gridExtra)
B <- 10^5
M <- replicate(B, {
  X <- sample(income, N)
  median(X)
})
p1 <- qplot(M, bins = 30, color = I("black"))
p2 <- qplot(sample = scale(M)) + geom_abline()
grid.arrange(p1, p2, ncol = 2)

mean(M)
sd(M)

B <- 10^5
M_star <- replicate(B, {
  X_star <- sample(X, N, replace = TRUE)
  median(X_star)
})

tibble(monte_carlo = sort(M), bootstrap = sort(M_star)) %>%
  qplot(monte_carlo, bootstrap, data = .) + 
  geom_abline()

quantile(M, c(0.05, 0.95))
quantile(M_star, c(0.05, 0.95))

median(X) + 1.96 * sd(X) / sqrt(N) * c(-1, 1)

mean(M) + 1.96 * sd(M) * c(-1,1)

mean(M_star) + 1.96 * sd(M_star) * c(-1, 1)


----------------------------------------------------------------------------------------------------
library(dslabs)
library(caret)
data(mnist_27)
# set.seed(1995) # if R 3.5 or earlier
set.seed(1995, sample.kind="Rounding") # if R 3.6 or later
indexes <- createResample(mnist_27$train$y, 10)

# Q1
# How many times do 3, 4, and 7 appear in the first resampled index?
sum(indexes[[1]] == 3)
sum(indexes[[1]] == 3)
sum(indexes[[1]] == 7)

# Q2
# What is the total number of times that 3 appears in all of the resampled indexes?
i=1
r = 0
while (i<=10) {
  r <- r + sum(indexes[[i]] == 3)
  i <- i+1
}
r
x=sapply(indexes, function(ind){
  sum(ind == 3)
})
sum(x)

# Q3
# What is the expected value and standard error of the 75th quantile?
y <- rnorm(100, 0, 1)
quantile(y, 0.75)
set.seed(1, sample.kind="Rounding")

res <- replicate(10000, {
  y <- rnorm(100, 0, 1)
  q <- quantile(y, 0.75)
})
mean(res)

# Q4
# Use 10 bootstrap samples to estimate the expected value and standard error of the 75th quantile.
set.seed(1,sample.kind = "Rounding")
y <- rnorm(100, 0, 1)
set.seed(1,sample.kind = "Rounding")
indexes <- createResample(y, 10)

q_75_star <- sapply(indexes, function(ind){
  quantile(y[ind], 0.75)
})
q_75_star
mean(q_75_star)
sd(q_75_star)

# Q5
# epeat the exercise from Q4 but with 10,000 bootstrap samples instead of 10. Set the seed to 1 first.

set.seed(1,sample.kind = "Rounding")
y <- rnorm(100, 0, 1)
set.seed(1,sample.kind = "Rounding")
indexes <- createResample(y, 10000)

q_75_star <- sapply(indexes, function(ind){
  quantile(y[ind], 0.75)
})
q_75_star
mean(q_75_star)
sd(q_75_star)

